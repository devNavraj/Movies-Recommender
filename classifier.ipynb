{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "future-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "authorized-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\praab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "czech-touch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mention watch 1 oz episode youll...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production film technique una...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think wonderful way spend time hot summer week...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake think ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stun f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>think movie right good job wasnt creative orig...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad act idiotic direct a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>catholic teach parochial elementary school nun...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im go disagree previous comment side maltin on...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expect star trek movies high art fan expec...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one reviewers mention watch 1 oz episode youll...  positive\n",
       "1      wonderful little production film technique una...  positive\n",
       "2      think wonderful way spend time hot summer week...  positive\n",
       "3      basically theres family little boy jake think ...  negative\n",
       "4      petter matteis love time money visually stun f...  positive\n",
       "...                                                  ...       ...\n",
       "49995  think movie right good job wasnt creative orig...  positive\n",
       "49996  bad plot bad dialogue bad act idiotic direct a...  negative\n",
       "49997  catholic teach parochial elementary school nun...  negative\n",
       "49998  im go disagree previous comment side maltin on...  negative\n",
       "49999  one expect star trek movies high art fan expec...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the IMDB dataset \n",
    "dataset = pd.read_csv('imdb_data.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-nelson",
   "metadata": {},
   "source": [
    "## Labelling the sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "velvet-syndicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Labeling the sentiment data\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "# Transformed sentiment data\n",
    "sentiment_data = lb.fit_transform(dataset['sentiment'])\n",
    "print(sentiment_data.shape)\n",
    "print(sentiment_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-report",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "african-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reviews, X_test_reviews, y_train_sentiments, y_test_sentiments = train_test_split(\n",
    "    dataset['review'], sentiment_data, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "false-lewis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39087    thats keep ask many fight scream match swear g...\n",
      "30893    watch entire movie could watch entire movie st...\n",
      "45278    touch love story reminiscent mood love draw he...\n",
      "16398    latterday fulci schlocker totally abysmal conc...\n",
      "13653    first firmly believe norwegian movies continua...\n",
      "                               ...                        \n",
      "11284    shadow magic recapture joy amazement first mov...\n",
      "44732    find movie quite enjoyable fairly entertain go...\n",
      "38158    avoid one terrible movie excite pointless murd...\n",
      "860      production quite surprise absolutely love obsc...\n",
      "15795    decent movie although little bite short time p...\n",
      "Name: review, Length: 40000, dtype: object\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_reviews)\n",
    "print(y_train_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-thompson",
   "metadata": {},
   "source": [
    "## Vectorizing the reviews text for both train and test datasets using TF-IDF as a feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indian-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tfidf vectorizer\n",
    "tv = TfidfVectorizer(ngram_range = (1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mineral-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformed train reviews\n",
    "tv_train_reviews = tv.fit_transform(X_train_reviews)\n",
    "\n",
    "# Transformed test reviews\n",
    "tv_test_reviews = tv.transform(X_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "informal-bracket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train_reviews: (40000, 6984669)\n",
      "Tfidf_test_reviews: (10000, 6984669)\n"
     ]
    }
   ],
   "source": [
    "print('Tfidf_train_reviews:', tv_train_reviews.shape)\n",
    "print('Tfidf_test_reviews:', tv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-maximum",
   "metadata": {},
   "source": [
    "## Training and fitting the dataset using Multinomial Naive Bayes model \n",
    "From our earlier sentiment analysis, it is evident that Multinomial Naive Bayes Classifier has better accuracy in all evaluation metrics compared to other along with minimum training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "meaning-yukon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Multinomial Naive Bayes Classifier\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# Fitting the Multinomial Naive Bayes Classifier for Tfidf features\n",
    "mnb.fit(tv_train_reviews, y_train_sentiments.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pacific-edgar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the model for Tfidf features\n",
    "mnb_tfidf_predictions = mnb.predict(tv_test_reviews)\n",
    "print(mnb_tfidf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "offshore-insertion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb_tfidf_score: 0.8903\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score for Tfidf features\n",
    "mnb_tfidf_score = accuracy_score(y_test_sentiments, mnb_tfidf_predictions)\n",
    "print(\"mnb_tfidf_score:\", mnb_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "coral-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializing the Multinomial Naive Bayes Classifier using pickle and saving it for our final implementation\n",
    "pickle.dump(mnb, open('pickle/classifier.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-dinner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
